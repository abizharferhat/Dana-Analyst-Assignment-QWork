pandas==1.5.3


# Collect and Load data into database

import sqlite3
import pandas as pd
import numpy as np


##Connect to the SQLite database
conn = sqlite3.connect('F:\\assignment\\jobdb.sqlite')
cur = conn.cursor()

##Load the data into pandas dataframes
job_main_df = pd.read_sql_query("SELECT * FROM job_main", conn)
responsibilities_df = pd.read_csv("C:\\Users\\Administrator\\Downloads\\responsibilities.csv")

print("Job Postings Data:")
print(job_main_df.head())
print("\nResponsibilities Data:")
print(responsibilities_df.head())


# Cleaning Responsibilities text
from collections import Counter
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

## Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

## Preprocess text data
def preprocess_text(text):
    
    tokens = word_tokenize(text.lower())
    
    tokens = [token for token in tokens if token not in string.punctuation and token not in stopwords.words('english')]
    return tokens

##Concatenate responsibilities text
responsibilities_text = ' '.join(responsibilities_df['responsibility'])

responsibilities_tokens = preprocess_text(responsibilities_text)

responsibilities_freq = Counter(responsibilities_tokens)

print("Most common responsibilities:")
print(responsibilities_freq.most_common(20))


# Data Cleaning And Exploration 


## Check the data 
job_main_df()


## Remove Unnecessary Column 
job_main_df.drop(['webid', 'companyid', 'date_scraped', 'date_posted', 'source', 'last_seen','date_expired', 'year_experience_max'], axis=1, inplace=True)

job_main_df.info()


## Create Salary Column
job_main_df['salary'] = (job_main_df['salary_min'] + job_main_df['salary_max'])

## Change Column name 
job_main_df.rename(columns = {'year_experience_min' : 'year_experience'},inplace=True)

## Create Experience level Segment
job_main_df["experience_level"] = pd.cut(job_main_df["year_experience"], bins=[0,3,6,10], labels=["Entry Level", "Middle Level", "Senior Level"])


# Remove Non value in the column 

## Sum non value in each column
job_main_df.isnull().sum()

## Drop Non Value in Salary and Experience Level 
job_main_df.dropna(subset = ['salary', 'experience_level'],inplace = True)

job_main_df.isnull().sum()


## Replace Non value into Non-specific

job_main_df['remote'].fillna("Non-Specific", inplace=True)

replace = {0: 'No', 1: 'Yes'}
job_main_df['remote'] = job_main_df['remote'].replace(replace)


## Check Unique value in Remote Column
job_main_df['remote'].unique()


## Count the employee of Remote Work
job_main_df['remote'].value_counts()

# Replace Column Name 

job_main_df.rename(columns = {'currency' : 'location'},inplace=True)


## Replace Value in The Column
job_main_df['location']=job_main_df['location'].str.replace('SGD', 'Singapore')
job_main_df['location']=job_main_df['location'].str.replace('MYR', 'Malaysia')
job_main_df['location']=job_main_df['location'].str.replace('RM', 'Malaysia')
job_main_df['location']=job_main_df['location'].str.replace('IDR', 'Indonesia')

# Count value of Location
job_main_df['location'].value_counts()


# Create Fair Salary Range Column And Calculation by Grouping Data
grouped_data = job_main_df.groupby('job_title').agg({'salary_min': 'mean', 'salary_max': 'mean'}).reset_index()

## Calculate fair salary range for each job title
grouped_data['fair_salary_range'] = grouped_data['salary_max'] - grouped_data['salary_min']

print(grouped_data)


# Merge Fair Salary Range into data column
job_main_df = pd.merge(job_main_df, grouped_data[['job_title', 'fair_salary_range']], on='job_title', how='left')


# Count the top 10 job in the data
job_main_df['job_title'].value_counts().nlargest(10)

## Replace the name of the top 10 name

job_main_df['job_title']=job_main_df['job_title'].str.replace('Sales and Marketing Executive', 'Sales & Marketing Executive')
job_main_df['job_title']=job_main_df['job_title'].str.replace('SALES & Marketing Executive', 'Sales & Marketing Executive')
job_main_df['job_title']=job_main_df['job_title'].str.replace('DIGITAL Marketing Executive', 'Digital Marketing Executive')
job_main_df['job_title']=job_main_df['job_title'].str.replace('MARKETING EXECUTIVE', 'Marketing Executive')


## Check it if the data already change
job_main_df['job_title'].value_counts().nlargest(10)



# load Data of type of work into database
job_type_df = pd.read_sql_query("SELECT * FROM job_type", conn)
print("Job type Data:")
print(job_type_df.head())


# Merge the data with job_main
data_merged =pd.merge(job_main_df, job_type_df, on='scrapedid')
data_merged()


# Check the unique value of type
data_merged['type'].unique()

## Replace the name of values
data_merged['type']=data_merged['type'].str.replace('full_time', 'full-time')
data_merged['type']=data_merged['type'].str.replace('part_time', 'part-time')


## Count value in type of work
data_merged['type'].value_counts()

# Create the group calculation of Fair Salary Range by its experience and location
group_data = job_main_df.groupby(['experience_level', 'location'])['fair_salary_range'].sum().reset_index()
print(group_data)


# Create the group calculation of Fair Salary Range by type of work
group_data2 = data_merged.groupby('type')['fair_salary_range'].sum().sort_values()
group_data2







